{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce211d34",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "Endogenous Rhythmic Attention project, 2019-2022\n",
    "\n",
    "<b>Author</b>: Olof J. van der Werf\n",
    "<br><b>Last updated</b>: 10-08-2022\n",
    "\n",
    "[reference + DOI to publication]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8732c4bc",
   "metadata": {},
   "source": [
    "### Purpose of this notebook\n",
    "\n",
    "This notebook preprocesses the data before data analysis.\n",
    "\n",
    "<ul>\n",
    "<li> Convolute trials with a Gaussian, creating time series </li>\n",
    "<li> Detrending data </li>\n",
    "<li> Permuting the data for analysis </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7717f111",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dee9a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007dd0d2",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff778e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# element-wise convolution with a gaussian in the time domain\n",
    "def convolute(data):\n",
    "    \n",
    "    # element-wise subtraction to put in gaussian function\n",
    "    arr = []\n",
    "    for t in data['cue-target interval']:\n",
    "        arr.append(t - intervals)\n",
    "        \n",
    "    # gaussian function\n",
    "    W = np.exp(-(np.power(arr,2))/(2*sigma**2))\n",
    "\n",
    "    # element-wise multiplication of gussian with values\n",
    "    H = []\n",
    "    for i,interval in enumerate(intervals):\n",
    "        H.append(W[:,i] * data['rt'])\n",
    "    H = np.transpose(H)\n",
    "    \n",
    "    # take sum of each to get time series\n",
    "    W_sum = np.sum(W,0)\n",
    "    H_sum = np.sum(H,0)\n",
    "    ts = H_sum / W_sum\n",
    "    \n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9985df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# element-wise detrending of the data \n",
    "def detrend(data,ts):\n",
    "    coeff = np.polyfit(intervals,ts,1)\n",
    "    trend = np.polyval(coeff,intervals)\n",
    "    trend = pd.Series(trend,index = intervals)\n",
    "\n",
    "    detrended = data.copy()\n",
    "    detrended['rt'] = ''\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        detrended.loc[i,'rt'] = data.loc[i,'rt'] - trend[detrended.loc[i,'cue-target interval'],3] \n",
    "\n",
    "    return detrended\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc9979",
   "metadata": {},
   "source": [
    "### Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0be549d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder where the clean data is\n",
    "clean_data_folder = '/Volumes/fpn_rdm$/DM0874_OW_EndoRhythSamp/09_Data_after_cleaning/';\n",
    "\n",
    "# time bins\n",
    "start_time = 0.500\n",
    "end_time = 1.690\n",
    "resolution = 0.001\n",
    "num_time_bins = int((end_time - start_time) / resolution) + 2\n",
    "intervals = np.round(np.linspace(start_time, end_time, num = num_time_bins),3)\n",
    "\n",
    "# frequency bins\n",
    "low_freq = 2\n",
    "high_freq = 20\n",
    "resolution = 0.1\n",
    "num_freq_bins = int((high_freq - low_freq) / resolution) + 1\n",
    "frequencies =  np.linspace(low_freq, high_freq, num = num_freq_bins)\n",
    "\n",
    "# sigma of the Gaussian for the convolution\n",
    "sigma = 0.01\n",
    "\n",
    "# number of permutations\n",
    "nr_of_permutations = 1000\n",
    "\n",
    "# relevant condition lists\n",
    "conditions = ['60','80','100']\n",
    "validities = ['valid','invalid']\n",
    "visual_fields = ['left','right','both']\n",
    "subjects = ['03','04','05','06','09','11','12','14','15','17','18','19','20','21','26','27','30','31','32','33','34','35','37','38','39','40']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e8bbc6",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbd67f26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/fpn_rdm$/DM0874_OW_EndoRhythSamp/09_Data_after_cleaning/trials/trials.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m file \u001b[38;5;241m=\u001b[39m clean_data_folder \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrials/trials.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m trials \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcue-target interval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m trials\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/fpn_rdm$/DM0874_OW_EndoRhythSamp/09_Data_after_cleaning/trials/trials.csv'"
     ]
    }
   ],
   "source": [
    "file = clean_data_folder +'trials/trials.csv'\n",
    "trials = pd.read_csv(file, sep = ',', index_col = 0,dtype = 'str', converters = {'cue-target interval': float, 'rt': float})\n",
    "trials.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75803b19",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34c733",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Main loop\n",
    "data = {}\n",
    "time_series = {}\n",
    "\n",
    "# loop through validities\n",
    "for validity in validities:\n",
    "\n",
    "    data[validity] = {}\n",
    "    time_series[validity] = {}\n",
    "    \n",
    "    # loop through visual fields\n",
    "    for visual_field in visual_fields:\n",
    "\n",
    "        data[validity][visual_field] = {}\n",
    "        time_series[validity][visual_field] = {}\n",
    "            \n",
    "        # loop through conditions\n",
    "        for condition in conditions:\n",
    "            \n",
    "            if validity == 'invalid' and condition == '100':\n",
    "                continue\n",
    "                \n",
    "            data[validity][visual_field][condition] = pd.DataFrame()\n",
    "            \n",
    "            # take subset of data for each subject and preprocess data (detrending on the subject level)\n",
    "            for subject in subjects:\n",
    "            \n",
    "                # take a subset of the data with one condition (for pre-processing and time permutations)\n",
    "                subset = trials[(trials['subject'] == subject) & \n",
    "                                (trials['validity'] == validity) &\n",
    "                                (trials['visual field'] == visual_field) & \n",
    "                                (trials['condition'] == condition)]\n",
    "                \n",
    "                # convolute\n",
    "                ts = convolute(subset)\n",
    "                \n",
    "                # detrend\n",
    "                subset = detrend(subset,ts)\n",
    "                \n",
    "                # add to data\n",
    "                data[validity][visual_field][condition] = pd.concat((data[validity][visual_field][condition],subset))\n",
    "            \n",
    "            # reset index\n",
    "            data[validity][visual_field][condition] = data[validity][visual_field][condition].reset_index(drop = True)\n",
    "            \n",
    "            # create time series (for visualisation purposes)\n",
    "            time_series[validity][visual_field][condition] = convolute(data[validity][visual_field][condition])\n",
    "\n",
    "plt.plot(time_series[validity][visual_field][condition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d98fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time_series['valid']['left']['60'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "600fe5b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5  , 0.501, 0.502, ..., 1.698, 1.699, 1.7  ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals[0] = 0.500\n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d652cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cue-target interval label permutations\n",
    "interval_permutations = {}\n",
    "\n",
    "# loop through validities\n",
    "for validity in validities:\n",
    "\n",
    "    interval_permutations[validity] = {}\n",
    "    \n",
    "    # loop through visual fields\n",
    "    for visual_field in visual_fields:\n",
    "\n",
    "        interval_permutations[validity][visual_field] = {}\n",
    "            \n",
    "        # loop through conditions\n",
    "        for condition in conditions:\n",
    "            \n",
    "            if validity == 'invalid' and condition == '100':\n",
    "                continue\n",
    "                \n",
    "            interval_permutations[validity][visual_field][condition] = pd.DataFrame()\n",
    "            \n",
    "            # take subset of data for each subject and preprocess data\n",
    "            for subject in subjects:\n",
    "            \n",
    "                # take a subset of the data with one condition (for pre-processing and time permutations)\n",
    "                subset = trials[(trials['subject'] == subject) & \n",
    "                                (trials['validity'] == validity) &\n",
    "                                (trials['visual field'] == visual_field) & \n",
    "                                (trials['condition'] == condition)]\n",
    "                \n",
    "                perm = pd.DataFrame(index = )\n",
    "                \n",
    "                for i in range(nr_of_permutations):\n",
    "                    perm[i] = subset_one_condition.copy()\n",
    "                    perm[i]['cue-target interval'] = np.random.permutation(subset_one_condition[i]['cue-target interval'])\n",
    "                    \n",
    "                    # run through cue-permutations\n",
    "                    ts = convolute(perm[i])\n",
    "\n",
    "                    # detrend \n",
    "                    interval_permutations[i] = detrend(perm[i],ts)\n",
    "                \n",
    "                    # stLSS analysis\n",
    "                    \n",
    "                # convolute\n",
    "                ts = convolute(subset)\n",
    "                \n",
    "                # detrend\n",
    "                subset = detrend(subset,ts)\n",
    "                \n",
    "                # add to data\n",
    "                data[validity][visual_field][condition] = pd.concat((data[validity][visual_field][condition],subset))\n",
    "            \n",
    "            # reset index\n",
    "            data[validity][visual_field][condition] == data[validity][visual_field][condition].reset_index(drop = True)\n",
    "\n",
    "            \n",
    "            \n",
    " # shuffle cue-target interval labels\n",
    "                \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cedac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bedc7955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>validity</th>\n",
       "      <th>visual field</th>\n",
       "      <th>condition</th>\n",
       "      <th>cue-target interval</th>\n",
       "      <th>rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [subject, validity, visual field, condition, cue-target interval, rt]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "68a84176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>rt</th>\n",
       "      <th>condition</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.667</td>\n",
       "      <td>224.169577</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.700</td>\n",
       "      <td>160.521761</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.567</td>\n",
       "      <td>174.048930</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.550</td>\n",
       "      <td>272.652079</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.017</td>\n",
       "      <td>13.250922</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5899</th>\n",
       "      <td>1.583</td>\n",
       "      <td>-145.750205</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5900</th>\n",
       "      <td>1.567</td>\n",
       "      <td>-48.047096</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5901</th>\n",
       "      <td>1.650</td>\n",
       "      <td>-108.335474</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5902</th>\n",
       "      <td>0.633</td>\n",
       "      <td>88.505892</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>0.533</td>\n",
       "      <td>292.807324</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5904 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time          rt  condition  subject\n",
       "0     1.667  224.169577       60.0      3.0\n",
       "1     0.700  160.521761       60.0      3.0\n",
       "2     0.567  174.048930       60.0      3.0\n",
       "3     1.550  272.652079       60.0      3.0\n",
       "4     1.017   13.250922       60.0      3.0\n",
       "...     ...         ...        ...      ...\n",
       "5899  1.583 -145.750205       80.0     40.0\n",
       "5900  1.567  -48.047096       80.0     40.0\n",
       "5901  1.650 -108.335474       80.0     40.0\n",
       "5902  0.633   88.505892       80.0     40.0\n",
       "5903  0.533  292.807324       80.0     40.0\n",
       "\n",
       "[5904 rows x 4 columns]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  \n",
    "            \n",
    "                \n",
    "                            \n",
    "                # convolute\n",
    "                ts = convolution(subset)\n",
    "                \n",
    "                # detrend\n",
    "                subset = detrend(subset,ts)\n",
    "                \n",
    "                # add to data\n",
    "                data = pd.concat((data,subset))\n",
    "                \n",
    "                # run permutations\n",
    "                perm = {}\n",
    "                \n",
    "                    perm[i] = subset.copy()\n",
    "                    perm[i]['cue-target interval'] = np.random.permutation(perm[i]['cue-target interval'])\n",
    "                    \n",
    "                    # convolute\n",
    "                    ts = convolution(perm[i])\n",
    "                    \n",
    "                    # detrend \n",
    "                    interval_permutations[i] = detrend(perm[i],ts)\n",
    "                    \n",
    "                    # add to data\n",
    "                    \n",
    "                    \n",
    "# reset index of data\n",
    "data = data.reset_index(drop=True)\n",
    "            \n",
    "# save data\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "6a13b3ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     time          rt  condition\n",
      "0   1.383  -84.942343         60\n",
      "1   1.183   151.12452         60\n",
      "2   1.367  -27.156234         60\n",
      "3   0.750  -47.597592         60\n",
      "4   0.550  -121.83073         60\n",
      "..    ...         ...        ...\n",
      "62  1.583 -145.750205         60\n",
      "63  1.567  -48.047096         60\n",
      "64  1.650 -108.335474         60\n",
      "65  0.633   88.505892         60\n",
      "66  0.533  292.807324         60\n",
      "\n",
      "[67 rows x 3 columns]\n",
      "     time          rt  condition\n",
      "0   1.150  -84.942343         60\n",
      "1   1.400   151.12452         60\n",
      "2   0.800  -27.156234         60\n",
      "3   1.567  -47.597592         60\n",
      "4   0.617  -121.83073         60\n",
      "..    ...         ...        ...\n",
      "62  0.767 -145.750205         60\n",
      "63  0.833  -48.047096         60\n",
      "64  0.917 -108.335474         60\n",
      "65  1.333   88.505892         60\n",
      "66  0.983  292.807324         60\n",
      "\n",
      "[67 rows x 3 columns]\n",
      "     time          rt  condition\n",
      "0   1.383  -84.942343         60\n",
      "1   1.183   151.12452         60\n",
      "2   1.367  -27.156234         60\n",
      "3   0.750  -47.597592         60\n",
      "4   0.550  -121.83073         60\n",
      "..    ...         ...        ...\n",
      "62  1.583 -145.750205         60\n",
      "63  1.567  -48.047096         60\n",
      "64  1.650 -108.335474         60\n",
      "65  0.633   88.505892         60\n",
      "66  0.533  292.807324         60\n",
      "\n",
      "[67 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# stLSS analysis\n",
    "for validity in validities:\n",
    "    for visual_field in visual_fields:\n",
    "        for condition in conditions:\n",
    "            \n",
    "            \n",
    "            \n",
    "            powerspec = stLSS(data)\n",
    "            \n",
    "            \n",
    "            # time bin permutations\n",
    "            time_permutations = pd.DataFrame()\n",
    "            \n",
    "            for i in range(nr_of_permutations):\n",
    "                perm = data.copy()\n",
    "                perm['time'] = np.random.permutation(perm['time'])\n",
    "            \n",
    "            # convolute, detrend, stLSS\n",
    "            ts_perm = convolution(perm)\n",
    "            perm = detrend()\n",
    "            \n",
    "            \n",
    "        \n",
    "        # condition permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593001fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
