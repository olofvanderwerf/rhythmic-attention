{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce211d34",
   "metadata": {},
   "source": [
    "# Data preprocessing and analysis\n",
    "\n",
    "Endogenous Rhythmic Attention project, 2019-2022\n",
    "\n",
    "<b>Author</b>: Olof J. van der Werf\n",
    "<br><b>Last updated</b>: 10-08-2022\n",
    "\n",
    "[reference + DOI to publication]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8732c4bc",
   "metadata": {},
   "source": [
    "### Purpose of this notebook\n",
    "\n",
    "This notebook preprocesses the data before data analysis.\n",
    "\n",
    "<ul>\n",
    "<li> Convolute trials with a Gaussian, creating time series </li>\n",
    "<li> Detrending data </li>\n",
    "<li> Permuting the data for analysis </li>\n",
    "<li> Run stLSS analysis </li>\n",
    "<li> Save output </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7717f111",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee9a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007dd0d2",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff778e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# element-wise convolution with a gaussian in the time domain\n",
    "def convolute(data):\n",
    "    \n",
    "    # element-wise subtraction to put in gaussian function\n",
    "    arr = []\n",
    "    for t in data['cue-target interval']:\n",
    "        arr.append(t - intervals)\n",
    "    \n",
    "    # gaussian function\n",
    "    W = np.exp(-(np.power(arr,2))/(2*sigma**2))\n",
    "\n",
    "    # element-wise multiplication of gussian with values\n",
    "    H = []\n",
    "    for i,interval in enumerate(intervals):\n",
    "        H.append(W[:,i] * data['reaction time'])\n",
    "    H = np.transpose(H)\n",
    "    \n",
    "    # take sum of each to get time series\n",
    "    W_sum = np.sum(W,0)\n",
    "    H_sum = np.sum(H,0)\n",
    "    ts = H_sum / W_sum\n",
    "    \n",
    "    # turn into series\n",
    "    ts = pd.Series(ts, index = intervals)\n",
    "    \n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9985df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# element-wise detrending of the data \n",
    "def detrend(data,ts):\n",
    "    coeff = np.polyfit(intervals,ts,1)\n",
    "    trend = np.polyval(coeff,intervals)\n",
    "    trend = pd.Series(trend,index = intervals)\n",
    "    \n",
    "    detrended = data.copy()\n",
    "    detrended['reaction time'] = ''\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        detrended.loc[i,'reaction time'] = data.loc[i,'reaction time'] - trend[detrended.loc[i,'cue-target interval']] \n",
    "\n",
    "    return detrended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b31512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single trial least squares spectrum analysis\n",
    "def stLSS(data):\n",
    "    \n",
    "    # hanning taper\n",
    "    taper = pd.Series(np.hanning(len(intervals)),index = intervals)\n",
    "    taper = taper / np.sum(taper)\n",
    "    data = data.reset_index(drop=True)\n",
    "    for i, row in data.iterrows():\n",
    "        data.loc[i,'reaction time'] = data.loc[i,'reaction time'] * taper[data.loc[i,'cue-target interval']] \n",
    "\n",
    "    # stLSS\n",
    "    power_spectrum = pd.Series(index=frequencies,dtype='float64')\n",
    "    for frequency in frequencies:\n",
    "        phase = data['cue-target interval'] * 2 * np.pi * frequency\n",
    "        phase = phase.to_numpy()\n",
    "        x = [np.ones(len(data['cue-target interval'])),np.cos(phase),np.sin(phase)]\n",
    "        x = np.transpose(x)\n",
    "        y = np.transpose([data['reaction time'].to_numpy().astype('float64')])\n",
    "        x,resid,rank,s = np.linalg.lstsq(x,y,rcond=None)\n",
    "        power_spectrum[frequency] = complex(x[1][0],x[2][0])\n",
    "    \n",
    "    power_spectrum = abs(power_spectrum)**2\n",
    "        \n",
    "    return power_spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc9979",
   "metadata": {},
   "source": [
    "### Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be549d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder where the clean data is\n",
    "clean_data_folder = 'data/data_after_cleaning/'\n",
    "results_folder = 'data/results/'\n",
    "\n",
    "# time bins\n",
    "start_time = 0.490\n",
    "end_time = 1.690\n",
    "resolution = 0.001\n",
    "num_time_bins = int((end_time - start_time) / resolution) + 2\n",
    "intervals = np.round(np.linspace(start_time, end_time, num = num_time_bins),3)\n",
    "\n",
    "# frequency bins\n",
    "low_freq = 2\n",
    "high_freq = 20\n",
    "resolution = 0.1\n",
    "num_freq_bins = int((high_freq - low_freq) / resolution) + 1\n",
    "frequencies =  np.linspace(low_freq, high_freq, num = num_freq_bins)\n",
    "\n",
    "# sigma of the Gaussian for the convolution\n",
    "sigma = 0.01\n",
    "\n",
    "# permutations\n",
    "nr_of_permutations = 1000\n",
    "permutations = np.linspace(1,nr_of_permutations,nr_of_permutations).astype(int)\n",
    "\n",
    "# relevant condition lists\n",
    "conditions = ['60','80','100']\n",
    "validities = ['valid','invalid']\n",
    "visual_fields = ['left','right','both']\n",
    "subjects = ['03','04','05','06','09','11','12','14','15','17','18','19','20','21','26','27','30','31','32','33','34','35','37','38','39','40']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e8bbc6",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbd67f26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>condition</th>\n",
       "      <th>validity</th>\n",
       "      <th>cue side</th>\n",
       "      <th>cue-target interval</th>\n",
       "      <th>reaction time</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03</td>\n",
       "      <td>60</td>\n",
       "      <td>valid</td>\n",
       "      <td>right</td>\n",
       "      <td>1.500</td>\n",
       "      <td>674.346</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03</td>\n",
       "      <td>60</td>\n",
       "      <td>valid</td>\n",
       "      <td>right</td>\n",
       "      <td>1.033</td>\n",
       "      <td>535.099</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03</td>\n",
       "      <td>60</td>\n",
       "      <td>invalid</td>\n",
       "      <td>right</td>\n",
       "      <td>1.667</td>\n",
       "      <td>677.154</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03</td>\n",
       "      <td>60</td>\n",
       "      <td>invalid</td>\n",
       "      <td>right</td>\n",
       "      <td>0.700</td>\n",
       "      <td>642.355</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03</td>\n",
       "      <td>60</td>\n",
       "      <td>valid</td>\n",
       "      <td>left</td>\n",
       "      <td>1.200</td>\n",
       "      <td>649.998</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>03</td>\n",
       "      <td>60</td>\n",
       "      <td>valid</td>\n",
       "      <td>right</td>\n",
       "      <td>0.983</td>\n",
       "      <td>453.680</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>03</td>\n",
       "      <td>60</td>\n",
       "      <td>valid</td>\n",
       "      <td>right</td>\n",
       "      <td>1.517</td>\n",
       "      <td>466.662</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>03</td>\n",
       "      <td>60</td>\n",
       "      <td>valid</td>\n",
       "      <td>left</td>\n",
       "      <td>0.917</td>\n",
       "      <td>478.815</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>03</td>\n",
       "      <td>60</td>\n",
       "      <td>invalid</td>\n",
       "      <td>left</td>\n",
       "      <td>0.567</td>\n",
       "      <td>659.850</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>03</td>\n",
       "      <td>60</td>\n",
       "      <td>valid</td>\n",
       "      <td>right</td>\n",
       "      <td>0.634</td>\n",
       "      <td>675.943</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject condition validity cue side  cue-target interval  reaction time  \\\n",
       "0      03        60    valid    right                1.500        674.346   \n",
       "1      03        60    valid    right                1.033        535.099   \n",
       "2      03        60  invalid    right                1.667        677.154   \n",
       "3      03        60  invalid    right                0.700        642.355   \n",
       "4      03        60    valid     left                1.200        649.998   \n",
       "5      03        60    valid    right                0.983        453.680   \n",
       "6      03        60    valid    right                1.517        466.662   \n",
       "7      03        60    valid     left                0.917        478.815   \n",
       "8      03        60  invalid     left                0.567        659.850   \n",
       "9      03        60    valid    right                0.634        675.943   \n",
       "\n",
       "  response  \n",
       "0  correct  \n",
       "1  correct  \n",
       "2  correct  \n",
       "3  correct  \n",
       "4  correct  \n",
       "5  correct  \n",
       "6  correct  \n",
       "7  correct  \n",
       "8  correct  \n",
       "9  correct  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = clean_data_folder +'trials.csv'\n",
    "trials = pd.read_csv(file, sep = ',', index_col = 0,dtype = 'str', converters = {'cue-target interval': float, 'reaction time': float})\n",
    "trials.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75803b19",
   "metadata": {},
   "source": [
    "## Run main pre-processing and analysis loop\n",
    "\n",
    "Steps in this loop:\n",
    "<ul>\n",
    "<li> Filter data for the specific factor (validity, visual field, cue validity condition) </li>\n",
    "<li> Convoluting trials to obtain a time series of reaction time accross cue-target intervals </li>\n",
    "<li> Detrending trials </li>\n",
    "<li> Run stLSS analysis </li>\n",
    "<li> Save output </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e34c733",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Main loop\n",
    "# loop through validities\n",
    "for validity in validities:\n",
    "    \n",
    "    # loop through visual fields\n",
    "    for visual_field in visual_fields:\n",
    "            \n",
    "        # loop through conditions\n",
    "        for condition in conditions:\n",
    "            \n",
    "            if validity == 'invalid' and condition == '100':\n",
    "                continue\n",
    "            \n",
    "            # filter the data\n",
    "            if visual_field == 'both':\n",
    "                # take a subset of the data with one condition (for pre-processing purposes)\n",
    "                filtered = trials[(trials['validity'] == validity) &\n",
    "                                (trials['condition'] == condition) &\n",
    "                                (trials['response'] == 'correct')]\n",
    "            else:\n",
    "                # take a subset of the data with one condition (for pre-processing purposes)\n",
    "                filtered = trials[(trials['validity'] == validity) &\n",
    "                                (trials['cue side'] == visual_field) & \n",
    "                                (trials['condition'] == condition) &\n",
    "                                (trials['response'] == 'correct')]  \n",
    "            \n",
    "            # reset index\n",
    "            filtered = filtered.reset_index(drop = True)\n",
    "            \n",
    "            # convolute\n",
    "            time_series = convolute(filtered)\n",
    "                \n",
    "            # save time series\n",
    "            file = results_folder + 'time_series/' + validity + '_' + visual_field + '_' + condition + '.csv'\n",
    "            #time_series.to_csv(file,index = True, header = True)\n",
    "            \n",
    "            # detrend\n",
    "            detrended = detrend(filtered,time_series)\n",
    "            \n",
    "            # stLSS\n",
    "            power_spectrum = stLSS(detrended)\n",
    "\n",
    "            # save power spectrum\n",
    "            file = results_folder + 'power_spectra/' + validity + '_' + visual_field + '_' + condition + '.csv'\n",
    "            #power_spectrum.to_csv(file,index = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3877bb",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Permute cue-target intervals\n",
    "Here, we shuffle cue-target interval labels, in order to compare our observed reaction times against them. We repeat all above analysis steps for each permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d652cadc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cue-target interval label permutations\n",
    "# loop through validities\n",
    "for validity in validities:\n",
    "    \n",
    "    # loop through visual fields\n",
    "    for visual_field in visual_fields:\n",
    "        \n",
    "        # loop through conditions\n",
    "        for condition in conditions:\n",
    "            \n",
    "            st = time.time()\n",
    "            \n",
    "            interval_permutations = pd.DataFrame()\n",
    "            \n",
    "            if validity == 'invalid' and condition == '100':\n",
    "                continue\n",
    "                \n",
    "               # filter the data\n",
    "            if visual_field == 'both':\n",
    "                # take a subset of the data with one condition (for pre-processing purposes)\n",
    "                filtered = trials[(trials['validity'] == validity) &\n",
    "                                (trials['condition'] == condition) &\n",
    "                                (trials['response'] == 'correct')]\n",
    "            else:\n",
    "                # take a subset of the data with one condition (for pre-processing purposes)\n",
    "                filtered = trials[(trials['validity'] == validity) &\n",
    "                                (trials['cue side'] == visual_field) & \n",
    "                                (trials['condition'] == condition) &\n",
    "                                (trials['response'] == 'correct')]  \n",
    "                        \n",
    "            # set index of filtered (to later be able to align all permutations)\n",
    "            filtered = filtered.reset_index(drop=True)\n",
    "            #filtered['index'] = filtered.index \n",
    "            \n",
    "            permutation = filtered.copy()\n",
    "            \n",
    "            for i in permutations:\n",
    "                # get the start time\n",
    "                \n",
    "                # print \n",
    "                print('Validity: {}, visual field: {}, condition: {}, permutation: {}'.format(validity,visual_field, condition, i),end = '       \\r')\n",
    "                #sys.stdout.flush()\n",
    "                \n",
    "                # shuffle data\n",
    "                permutation['cue-target interval'] = np.random.permutation(permutation['cue-target interval'])\n",
    "                \n",
    "                # convolute\n",
    "                time_series = convolute(permutation)\n",
    "\n",
    "                # detrend\n",
    "                detrended = detrend(permutation,time_series)\n",
    "\n",
    "                # stLSS\n",
    "                interval_permutations[i] = stLSS(detrended)\n",
    "                \n",
    "            # plot data\n",
    "            print('Surrogate power spectrum for '+validity+' trials in '+visual_field+' visual field(s), '+condition+'% cue validity:')\n",
    "            plt.plot(interval_permutations.mean(axis=1))\n",
    "            plt.ylabel('power [a.u.]')\n",
    "            plt.xlabel('frequency (Hz)')\n",
    "            plt.show()\n",
    "            \n",
    "            # save data\n",
    "            file = results_folder + 'permutations/interval_permutations/' + validity + '_' + visual_field + '_' + condition + '.csv'\n",
    "            #interval_permutations.to_csv(file,index = True, header = True)\n",
    "            \n",
    "            # get the end time\n",
    "            et = time.time()\n",
    "\n",
    "            # get the execution time\n",
    "            elapsed_time = round(et - st)\n",
    "            print('Execution time for this factor:', elapsed_time, 'seconds  \\r')\n",
    "            #sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f0de7a",
   "metadata": {},
   "source": [
    "### Permute condition labels\n",
    "Here, we shuffle condition labels, in order to compare our observed reaction times against them (for the 'valid' trials). We repeat all above analysis steps for each permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d478a6aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Condition label permutations\n",
    "# [only 'valid' trials are taken into consideration]\n",
    "\n",
    "# loop through visual fields\n",
    "for visual_field in visual_fields:\n",
    "    \n",
    "    st = time.time()\n",
    "    \n",
    "    condition_permutations = pd.DataFrame(columns = ['cue-target interval'])\n",
    "\n",
    "    # filter the data\n",
    "    if visual_field == 'both':\n",
    "        # take a subset of the data with one factor\n",
    "        filtered = trials[(trials['validity'] == 'valid') &\n",
    "                          (trials['response'] == 'correct')]\n",
    "    else:\n",
    "        # take a subset of the data with one factor\n",
    "        filtered = trials[(trials['validity'] == 'valid') &\n",
    "                          (trials['cue side'] == visual_field) & \n",
    "                          (trials['response'] == 'correct')]\n",
    "    \n",
    "    filtered = filtered.reset_index(drop=True)\n",
    "    filtered['index'] = filtered.index\n",
    "    \n",
    "    # initiate permutation dataframe\n",
    "    condition_permutations = {}\n",
    "    for condition in conditions:\n",
    "        condition_permutations[condition] = pd.DataFrame()\n",
    "    \n",
    "    for i in permutations:\n",
    "        \n",
    "        permutation = pd.DataFrame()\n",
    "        \n",
    "        # loop through subjects\n",
    "        for subject in subjects:\n",
    "\n",
    "            # copy subset (just like above) and shuffle the condition labels\n",
    "            subject_permutation = filtered[filtered['subject'] == subject].copy()\n",
    "            subject_permutation['condition'] = np.random.permutation(subject_permutation['condition'])\n",
    "            \n",
    "            permutation = pd.concat((permutation,subject_permutation),ignore_index=True)\n",
    "\n",
    "        # loop through conditions\n",
    "        for condition in conditions:\n",
    "                \n",
    "            # Print\n",
    "            print('visual field: {}, permutation: {}'.format(visual_field, i),end = '       \\r')\n",
    "            #sys.stdout.flush()\n",
    "\n",
    "            # take subset for subject\n",
    "            subset_one_condition = permutation[permutation['condition'] == condition]\n",
    "\n",
    "            # run through cue-permutations\n",
    "            ts = convolute(subset_one_condition)\n",
    "\n",
    "            # detrend \n",
    "            subset_one_condition = detrend(subset_one_condition,ts)\n",
    "\n",
    "            # add to subject permutations for all conditions\n",
    "            condition_permutations[condition][i] = stLSS(subset_one_condition)\n",
    "    \n",
    "    # save data          \n",
    "    for condition in conditions:\n",
    "        \n",
    "        file = results_folder + 'permutations/condition_permutations/valid_' + visual_field + '_' + condition + '.csv'\n",
    "        #condition_permutations[condition].to_csv(file,index = True, header = True)\n",
    "\n",
    "    # get the end time\n",
    "    et = time.time()\n",
    "\n",
    "    # get the execution time\n",
    "    elapsed_time = round(et - st)\n",
    "    print('Execution time for one visual field:', elapsed_time, 'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data          \n",
    "for condition in conditions:\n",
    "\n",
    "    file = results_folder + 'permutations/condition_permutations/' + validity + '_' + visual_field + '_' + condition + '.csv'\n",
    "    #condition_permutations[condition].to_csv(file,index = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db8029",
   "metadata": {},
   "source": [
    "The end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
